{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 四、调用讯飞星火"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 讯飞星火认知大模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "讯飞星火认知大模型，由科大讯飞于2023年5月推出的中文大模型，也是国内大模型的代表产品之一。同样，受限于中文语境与算力资源，星火在使用体验上与 ChatGPT 还存在差异，但是，作为与文心不分伯仲的国内中文大模型，仍然值得期待与尝试。相较于存在显著资源、技术优势的百度，科大讯飞想要杀出重围，成为国内大模型的佼佼者，需要充分利用相对优势，至少目前来看，星火并未掉队。同时，不知道是否因为讯飞 API 还没有全面开放，讯飞 API 的测试使用效果比文心更好，值得期待。\n",
    "\n",
    "目前，讯飞星火大模型 API 已进入 $\\beta$ 测试阶段，每一个讯飞账户都可以申请若干 token 的试用。但是，相对于文心与 GPT 几乎完全一致的 API 调用方式，星火 API 需要使用 WebSocket 来进行调用，对企业友好，但对初学者、新手开发者来说调用难度较大。本章节将指导开发者如何将星火 API 封装为可直接通过 request 调用的 API 接口从而和其他大模型保持一致，也将介绍如何将其封装成个性化 LLM 嵌入 LangChain 使用。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 申请调用权限"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "相对于文心复杂的申请流程，讯飞的权限申请显得简单易操作得多：\n",
    "\n",
    "首先进入到[星火认知大模型首页](https://xinghuo.xfyun.cn/sparkapi)，点击“免费试用”："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../../figures/spark_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果是没有领取过免费试用包的用户，可以领取到 100000 token 的试用量；如果已领取过，就会自动跳转到下方购买产品的页面。完成领取后，点击上文中的“服务管理”即可进入控制台："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../../figures/spark_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在该界面，我们就可以看到我们获取到的 `APPID`、`APISecret` 和 `APIKey` 了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 调用原生星火 API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "星火 API 需要通过 WebSocket 进行连接，相对来说配置较为复杂，讯飞给出了配置示例 SparkApi.py 和连接示例 test.py，此处我们仅讲解 test.py 里的调用逻辑，配置示例代码直接使用即可。\n",
    "\n",
    "注意，需要在环境中安装配置示例中的所需第三方库。\n",
    "\n",
    "首先我们需要配置秘钥信息："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import SparkApi\n",
    "#以下密钥信息从控制台获取\n",
    "appid = \"\"     #填写控制台中获取的 APPID 信息\n",
    "api_secret = \"\"   #填写控制台中获取的 APISecret 信息\n",
    "api_key =\"\"    #填写控制台中获取的 APIKey 信息\n",
    "\n",
    "#用于配置大模型版本，默认“general/generalv2”\n",
    "domain = \"general\"   # v1.5版本\n",
    "# domain = \"generalv2\"    # v2.0版本\n",
    "\n",
    "#云端环境的服务地址\n",
    "Spark_url = \"ws://spark-api.xf-yun.com/v1.1/chat\"  # v1.5环境的地址\n",
    "# Spark_url = \"ws://spark-api.xf-yun.com/v2.1/chat\"  # v2.0环境的地址"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "星火的调用传参和文心类似，也需要传入一个列表，列表中包括 role 和 prompt，我们首先定义一个从用户输入 prompt 生成传入参数的函数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getText(role, content, text = []):\n",
    "    # role 是指定角色，content 是 prompt 内容\n",
    "    jsoncon = {}\n",
    "    jsoncon[\"role\"] = role\n",
    "    jsoncon[\"content\"] = content\n",
    "    text.append(jsoncon)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接着，我们将一个用户输入 prompt 封装为这样一个传入参数列表："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user', 'content': '你好'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = getText(\"user\", \"你好\")\n",
    "question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后再调用 SparkApi.py 中封装的 main 函数即可："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你好！很高兴为您提供帮助。请问有什么问题我可以帮您解答吗？"
     ]
    }
   ],
   "source": [
    "response = SparkApi.main(appid,api_key,api_secret,Spark_url,domain,question)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 统一 API 调用方式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由于星火使用了 WebSocket 连接，不能直接使用 request 来进行访问，同其他大模型 API 访问方式具有一定差异。我们可以通过 FastAPI 将星火 API 封装成本地 API，从而实现统一的模型调用方式。我们在《附2 将大模型 API 封装成本地 API》中讲解了如何实现本地 API 的封装，此处仅讲解如何启动并调用本地 API。\n",
    "\n",
    "在我们完成本地 API 的封装后（spark_api.py），我们可以通过 uvicorn 命令启动："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! uvicorn spark_api:app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "启动之后，默认会在本地 8000 端口开启 API 服务。\n",
    "\n",
    "启动 API 之后，我们可以向本地 8000 端口发起 Request 请求来访问 API："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"你好！有什么我可以帮助你的吗？\"'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "api_url = \"http://127.0.0.1:8000/spark\"\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "data = {\n",
    "    \"prompt\" : \"你好\",\n",
    "    \"temperature\" : 0.2,\n",
    "    \"max_tokens\" : 3096}\n",
    "\n",
    "response = requests.post(api_url, headers=headers, json=data)\n",
    "response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同样，我们可以用一个函数来封装 requests 访问的细节："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion_spark(prompt, temperature = 0.1, max_tokens = 4096):\n",
    "\n",
    "    api_url = \"http://127.0.0.1:8000/spark\"\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    data = {\n",
    "        \"prompt\" : prompt,\n",
    "        \"temperature\" : temperature,\n",
    "        \"max_tokens\" : max_tokens}\n",
    "\n",
    "    response = requests.post(api_url, headers=headers, json=data)\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"你好！有什么我可以帮助你的吗？\"'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_completion_spark(\"你好\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "星火 API 同样可以制作成自定义 LLM 并接入 LangChain，制作方式同文心大模型，此处就不再赘述，如有需要可自行尝试。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zyh_llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
