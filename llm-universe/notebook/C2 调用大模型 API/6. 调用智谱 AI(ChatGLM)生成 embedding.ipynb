{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 六、调用智谱 AI 生成 embedding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 调用智谱 AI Embedding API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "智谱 AI 及 ChatGLM 在上一章已经进行了简单介绍，本章将介绍如何通过其获得文本的 embedding 的，以及将其封装成个性化 embedding 嵌入 LangChain 使用。关于什么是 embedding，具体作用为何，请参见第四部分《数据库搭建》。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zhipuai\n",
    "zhipuai.api_key = \"your api key\" #填写控制台中获取的 APIKey 信息\n",
    "\n",
    "model = \"text_embedding\" #选择调用生成 embedding 的模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "自定义要生产 embedding 的文本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"要生成 embedding 的输入文本，字符串形式。每个输入不得超过模型的最大输入tokens数量512\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "调用远程 API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = zhipuai.model_api.invoke(\n",
    "    model=model,\n",
    "    prompt=text\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "官方的 SDK 返回的结果是字典的格式，这里我们可以直接传入键获得值。\n",
    "\n",
    "我们通过查看 `code` 是否 == 200 来判断请求是否成功"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "print(response['code'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "返回的 embedding, token 等内容被存放在 `data` 中。我们可以查看生产 embedding 的长度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "生成的 embedding 长度为: 1024\n"
     ]
    }
   ],
   "source": [
    "print(f\"生成的 embedding 长度为: {len(response['data']['embedding'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于每次模型的调用来说，都是要消耗 token 的（花钱），token 的消耗都存放在 `data` 的 `usage` 中。 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一般情况下 ChatGLM 模型中 token 和字数的换算比例约为 1:1.8，但因为不同模型的分词不同，所以换算比例也存在差异，每一次实际处理 token 数量以模型返回为准。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以查看输入的 tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "用户输入的 tokens 数量为: 28\n"
     ]
    }
   ],
   "source": [
    "print(f\"用户输入的 tokens 数量为: {response['data']['usage']['prompt_tokens']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "用户输入的文本长度为: 52\n"
     ]
    }
   ],
   "source": [
    "print(f\"用户输入的文本长度为: {len(text)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "本次 token 和字数的换算比例为: 0.5384615384615384, 和理论值 1:1.8 = 0.5555555555555556 接近\n"
     ]
    }
   ],
   "source": [
    "print(f\"本次 token 和字数的换算比例为: {response['data']['usage']['prompt_tokens']/len(text)}, 和理论值 1:1.8 = {1/1.8} 接近\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因为模型其实没有生成新的文本，只是获取到输入的 embedding，所以 token 数为0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型输出的 tokens 数量为: 0\n"
     ]
    }
   ],
   "source": [
    "print(f\"模型输出的 tokens 数量为: {response['data']['usage']['completion_tokens']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总 tokens 数量为: 28\n"
     ]
    }
   ],
   "source": [
    "print(f\"总 tokens 数量为: {response['data']['usage']['total_tokens']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 使用 LangChain 调用智谱 AI Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们同样可以通过 LangChain 框架来调用智谱 AI 大模型，以将其接入到我们的应用框架中。\n",
    "\n",
    "原生的 LangChain 是不支持智谱 AI Embedding 调用的，我们需要自定义一个 Embedding。\n",
    "\n",
    "此处，我们可以直接调用已自定义好的 ZhipuAILLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zhipuai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zhipuai_embedding import ZhipuAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "zhipuai.api_key = \"xxx\"    #输入自己的 api_key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "zhipuai_embeddings = ZhipuAIEmbeddings(zhipuai_api_key=zhipuai.api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以生成 query 的 embedding。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.13970163464546204, 0.04416792839765549, 0.020967043936252594, -0.19684536755084991, 0.08451296389102936, -0.0685092955827713, -0.05186789482831955, 0.11296232044696808, 0.12375720590353012, 0.1507660448551178]\n"
     ]
    }
   ],
   "source": [
    "query_embedding = zhipuai_embeddings.embed_query('你好')\n",
    "\n",
    "print(query_embedding[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们也可以生成 doc_list 的 embedding。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_list = [\n",
    "    '你好',\n",
    "    '什么是机器学习',\n",
    "    '什么是深度学习',\n",
    "    '什么是大模型'\n",
    "]\n",
    "\n",
    "doc_embeddings = zhipuai_embeddings.embed_documents(doc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你好 的 embedding 为 [-0.13970163464546204, 0.04416792839765549, 0.020967043936252594, -0.19684536755084991, 0.08451296389102936, -0.0685092955827713, -0.05186789482831955, 0.11296232044696808, 0.12375720590353012, 0.1507660448551178]...\n",
      "\n",
      "什么是机器学习 的 embedding 为 [-0.04628180339932442, -0.09553179144859314, 0.010844158940017223, -0.1201983317732811, 0.16935010254383087, -0.15349552035331726, 0.17940732836723328, 0.1256963312625885, 0.09910263121128082, 0.1022590845823288]...\n",
      "\n",
      "什么是深度学习 的 embedding 为 [-0.09552870690822601, -0.03116282820701599, 0.11060678958892822, 0.08925414085388184, 0.06898286193609238, -0.07559530436992645, 0.2021033763885498, -0.04418506473302841, 0.10697835683822632, -0.0666293203830719]...\n",
      "\n",
      "什么是大模型 的 embedding 为 [0.10551410913467407, 0.1735556423664093, -0.24402201175689697, 0.02649446204304695, 0.09757085889577866, 0.030247822403907776, 0.4318920969963074, 0.06334380805492401, -0.02869655191898346, -0.1011139303445816]...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('\\n'.join([f'{doc} 的 embedding 为 {doc_embedding[:10]}...\\n' for doc, doc_embedding in zip(doc_list, doc_embeddings)]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
